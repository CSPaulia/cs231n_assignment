2023-12-18 20:46:42,855 - INFO - Your scores:
2023-12-18 20:46:42,855 - INFO - [[-0.81233741 -1.27654624 -0.70335995]
 [-0.17129677 -1.18803311 -0.47310444]
 [-0.51590475 -1.01354314 -0.8504215 ]
 [-0.15419291 -0.48629638 -0.52901952]
 [-0.00618733 -0.12435261 -0.15226949]]
2023-12-18 20:46:42,855 - INFO - correct scores:
2023-12-18 20:46:42,855 - INFO - [[-0.81233741 -1.27654624 -0.70335995]
 [-0.17129677 -1.18803311 -0.47310444]
 [-0.51590475 -1.01354314 -0.8504215 ]
 [-0.15419291 -0.48629638 -0.52901952]
 [-0.00618733 -0.12435261 -0.15226949]]
2023-12-18 20:46:42,856 - INFO - Difference between your scores and correct scores:
2023-12-18 20:46:42,856 - INFO - 3.6802720745909845e-08
2023-12-18 20:46:42,856 - INFO - Difference between your loss and correct loss:
2023-12-18 20:46:42,856 - INFO - 1.794120407794253e-13
2023-12-18 20:46:42,863 - INFO - W2 max relative error: 3.440708e-09
2023-12-18 20:46:42,864 - INFO - b2 max relative error: 4.447625e-11
2023-12-18 20:46:42,871 - INFO - W1 max relative error: 3.561318e-09
2023-12-18 20:46:42,872 - INFO - b1 max relative error: 2.738421e-09
2023-12-18 20:46:42,888 - INFO - Final training loss: 0.01563498761185679
2023-12-18 20:46:48,227 - INFO - Train data shape: (49000, 3072)
2023-12-18 20:46:48,228 - INFO - Train labels shape: (49000,)
2023-12-18 20:46:48,228 - INFO - Validation data shape: (1000, 3072)
2023-12-18 20:46:48,228 - INFO - Validation labels shape: (1000,)
2023-12-18 20:46:48,228 - INFO - Test data shape: (1000, 3072)
2023-12-18 20:46:48,228 - INFO - Test labels shape: (1000,)
2023-12-18 20:46:48,242 - INFO - iteration 0 / 1000: loss 2.302939
2023-12-18 20:46:49,213 - INFO - iteration 100 / 1000: loss 2.302427
2023-12-18 20:46:51,070 - INFO - iteration 200 / 1000: loss 2.298095
2023-12-18 20:46:52,805 - INFO - iteration 300 / 1000: loss 2.253179
2023-12-18 20:46:54,347 - INFO - iteration 400 / 1000: loss 2.152041
2023-12-18 20:46:56,078 - INFO - iteration 500 / 1000: loss 2.115062
2023-12-18 20:46:57,867 - INFO - iteration 600 / 1000: loss 2.067323
2023-12-18 20:46:58,989 - INFO - iteration 700 / 1000: loss 2.031150
2023-12-18 20:47:00,368 - INFO - iteration 800 / 1000: loss 1.968564
2023-12-18 20:47:01,922 - INFO - iteration 900 / 1000: loss 1.962258
2023-12-18 20:47:03,171 - INFO - Validation accuracy: 0.29
2023-12-18 20:47:03,419 - INFO - training improved model---------------------------------
2023-12-18 20:47:03,471 - INFO - iteration 0 / 2000: loss 2.304567
2023-12-18 20:47:07,800 - INFO - iteration 100 / 2000: loss 1.811210
2023-12-18 20:47:12,445 - INFO - iteration 200 / 2000: loss 1.592028
2023-12-18 20:47:17,639 - INFO - iteration 300 / 2000: loss 1.668645
2023-12-18 20:47:21,948 - INFO - iteration 400 / 2000: loss 1.612753
2023-12-18 20:47:26,136 - INFO - iteration 500 / 2000: loss 1.544612
2023-12-18 20:47:31,032 - INFO - iteration 600 / 2000: loss 1.541012
2023-12-18 20:47:35,601 - INFO - iteration 700 / 2000: loss 1.612006
2023-12-18 20:47:40,232 - INFO - iteration 800 / 2000: loss 1.465478
2023-12-18 20:47:45,288 - INFO - iteration 900 / 2000: loss 1.387026
2023-12-18 20:47:49,634 - INFO - iteration 1000 / 2000: loss 1.381234
2023-12-18 20:47:54,719 - INFO - iteration 1100 / 2000: loss 1.315372
2023-12-18 20:47:59,735 - INFO - iteration 1200 / 2000: loss 1.433530
2023-12-18 20:48:04,386 - INFO - iteration 1300 / 2000: loss 1.472661
2023-12-18 20:48:08,720 - INFO - iteration 1400 / 2000: loss 1.493697
2023-12-18 20:48:13,163 - INFO - iteration 1500 / 2000: loss 1.469434
2023-12-18 20:48:16,772 - INFO - iteration 1600 / 2000: loss 1.631583
2023-12-18 20:48:20,209 - INFO - iteration 1700 / 2000: loss 1.571146
2023-12-18 20:48:23,292 - INFO - iteration 1800 / 2000: loss 1.467535
2023-12-18 20:48:26,101 - INFO - iteration 1900 / 2000: loss 1.553305
2023-12-18 20:48:29,154 - INFO - Validation accuracy: 0.508
2023-12-18 20:48:29,322 - INFO - Test accuracy: 0.5
2023-12-18 20:48:29,484 - INFO - training model with adjuested reg---------------------------------
2023-12-18 20:48:29,534 - INFO - iteration 0 / 2000: loss 2.308531
2023-12-18 20:48:32,745 - INFO - iteration 100 / 2000: loss 1.851028
2023-12-18 20:48:36,756 - INFO - iteration 200 / 2000: loss 1.760142
2023-12-18 20:48:40,430 - INFO - iteration 300 / 2000: loss 1.699933
2023-12-18 20:48:43,288 - INFO - iteration 400 / 2000: loss 1.688513
2023-12-18 20:48:47,114 - INFO - iteration 500 / 2000: loss 1.699210
2023-12-18 20:48:50,902 - INFO - iteration 600 / 2000: loss 1.725444
2023-12-18 20:48:55,457 - INFO - iteration 700 / 2000: loss 1.737719
2023-12-18 20:49:00,116 - INFO - iteration 800 / 2000: loss 1.594313
2023-12-18 20:49:03,456 - INFO - iteration 900 / 2000: loss 1.565298
2023-12-18 20:49:07,862 - INFO - iteration 1000 / 2000: loss 1.615633
2023-12-18 20:49:11,333 - INFO - iteration 1100 / 2000: loss 1.628962
2023-12-18 20:49:14,976 - INFO - iteration 1200 / 2000: loss 1.662357
2023-12-18 20:49:18,529 - INFO - iteration 1300 / 2000: loss 1.672047
2023-12-18 20:49:21,941 - INFO - iteration 1400 / 2000: loss 1.667010
2023-12-18 20:49:25,435 - INFO - iteration 1500 / 2000: loss 1.597153
2023-12-18 20:49:28,514 - INFO - iteration 1600 / 2000: loss 1.711104
2023-12-18 20:49:31,545 - INFO - iteration 1700 / 2000: loss 1.667340
2023-12-18 20:49:34,653 - INFO - iteration 1800 / 2000: loss 1.549203
2023-12-18 20:49:38,501 - INFO - iteration 1900 / 2000: loss 1.776384
2023-12-18 20:49:42,065 - INFO - Validation accuracy: 0.482
2023-12-18 20:49:42,226 - INFO - Test accuracy: 0.479
2023-12-18 20:49:42,380 - INFO - training model with cosine annealing---------------------------------
2023-12-18 20:50:16,674 - INFO - Step 1000, Learning Rate: 0.0018090169943749475, loss: 1.6072157953848285
2023-12-18 20:50:49,111 - INFO - Step 2000, Learning Rate: 0.0013090169943749475, loss: 1.4461153162136442
2023-12-18 20:51:22,845 - INFO - Step 3000, Learning Rate: 0.0006909830056250527, loss: 1.3021568232409104
2023-12-18 20:51:54,713 - INFO - Step 4000, Learning Rate: 0.00019098300562505265, loss: 1.2162242712303875
2023-12-18 20:51:54,725 - INFO - Validation accuracy: 0.547
2023-12-18 20:51:54,875 - INFO - Test accuracy: 0.547
